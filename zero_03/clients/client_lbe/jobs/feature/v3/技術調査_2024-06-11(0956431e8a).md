技術調査_2024-06-11(0956431e8a)
---

## 技術調査(fine turning, cognitive search)
### Fine Turning
やっぱりまだ早い。

- 理由
  - 学習データの質と量を確保できるのか？怪しいよね。
  - そもそも学習にお金がかかる。使ってなくてもホストしている時間でお金がかかる。RAGでのチューニング後に考えること。
- OpenAI のガイドによるベストプラクティス（Qiitaから抜粋）
  - To fine-tune a model that performs better than using a high-quality prompt with our base models, you should provide at least a few hundred high-quality examples, ideally vetted by human experts. From there, performance tends to linearly increase with every doubling of the number of examples. Increasing the number of examples is usually the best and most reliable way of improving performance.
  - (ベースモデルに比べてパフォーマンスが優れたモデルを Fine-tuning するためには、数百の高品質な例を提供する必要があります。理想的には、人間の専門家によって審査されたものが望ましいです。そこから、例の数を倍々に増やすごとにパフォーマンスが線形的に向上する傾向があります。パフォーマンスを向上させる最も良い、かつ最も信頼性の高い方法は、例の数を増やすことです。)

### RAG（Retrieval Augmented Generation）
#### 簡単に説明すると...
- Cognitive Search にデータをいれる
- ユーザの質問を元に、AIが、Cognitive Search の DBから、適切なデータを取得する
- ユーザの質問文と組み合わせて、GPT4に質問する

💡AIが２種類登場しています

#### 効果
- 社内独自のデータに基づいて回答するようになる

#### 制限
- 抽象的な質問や、意味検索に引っかからない質問文に対しては、効果が薄い（とされている）

#### 例
- 状況：意味検索に引っかかるようなデータが入っていること
  - 「昨日の打ち合わせ内容は、ぺらぺらぺら、でした」
  - 「最近、会社は、ぺらぺらぺら、でした」
  - 「利益は、ぺらぺらぺら、でした」
  - 「案件は、ぺらぺらぺら、でした」
  - 「ゆうだいさんは、毎日、筋トレをします」
  - 「ゆうだいさんは、毎日、サバを食べます」
  - 「ゆうだいさんは、毎週、映画鑑賞をします」
##### うまくいくとされている例
ユーザ「昨日の打ち合わせ内容、なんだっけ？」
AI「打ち合わせ内容は、ぺらぺらぺら、でした」

#### 難しいとされている例
ユーザ「ゆうだいさんが、よくやることは？」
AI「ゆうだいさんは、雄大な景色を見るために、毎週のように山に登ります」
（意味検索にひかっからない）

#### 作戦
まずは、通常のGPTとして使う場合に、RAGを使う。
なんでも、RAGに学習させる。
RAGを充実させていくと、そのうち、提案書にも効果がでてくるかもしれない。
出てこなくても、そもそもGPTとしての利用価値が上がる。

#### 追加作戦
たとえばGraphRAGなどを使うと、難しい例でも回答してくれるようになる。
あるいは、Internetに繋がるRAGを使えば、検索したうえで、回答してくれるので、新しい気付きを得られるかもしれない。
RAGの技術は、発展中のため、状況に応じて、どのように賢くするかを選ぶ。
